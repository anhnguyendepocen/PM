{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mylesgartland/Documents/Courses/Predictive Models/PM/Week 3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add packages\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/Documents/Courses/Predictive Models/PM/Week 3\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mylesgartland/Documents/Courses/Predictive Models/PM/Week 3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "# Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'state', u'account_length', u'area_code', u'international_plan',\n",
      "       u'voice_mail_plan', u'number_vmail_messages', u'total_day_minutes',\n",
      "       u'total_day_calls', u'total_day_charge', u'total_eve_minutes',\n",
      "       u'total_eve_calls', u'total_eve_charge', u'total_night_minutes',\n",
      "       u'total_night_calls', u'total_night_charge', u'total_intl_minutes',\n",
      "       u'total_intl_calls', u'total_intl_charge',\n",
      "       u'number_customer_service_calls', u'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Target\n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1140aeb50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQS9JjTPoJalxBr0kNe7/A9HPOTMfL4IlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1140bfe90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.ix[:,1:].values, df.ix[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print features_test.shape\n",
    "print features_train.shape\n",
    "print target_test.shape\n",
    "print target_train.shape\n",
    "print \"Percent of Target that is Yes\", target_test.mean()\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.921\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.95      0.95      0.95      1708\n",
      " Fail = yes       0.73      0.72      0.73       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print \"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt)\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.93023256  0.90033223  0.93355482  0.93687708  0.91362126  0.93311037\n",
      "  0.91973244  0.92976589  0.93311037  0.909699  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92400360004000037"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print \"Cross Validation Score for each K\",scores\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1631   77]\n",
      " [  81  211]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5sBhZqU5cJhZaQ4cZlaaA4eZlfafXkF+14y4lrYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1179cae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      0.99      0.97      1708\n",
      "Churn = yes       0.96      0.68      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1699    9]\n",
      " [  92  200]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_rf)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94352159  0.94684385  0.94352159  0.96345515  0.94019934  0.95986622\n",
      "  0.95986622  0.94314381  0.94648829  0.9632107 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95101167790753216"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score for each K\",scores_rf\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1699    9]\n",
      " [  92  200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114531150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.698662 seconds\n",
      "[mean: 0.88900, std: 0.00567, params: {'max_features': 2}, mean: 0.90000, std: 0.00611, params: {'max_features': 3}, mean: 0.91267, std: 0.00748, params: {'max_features': 4}, mean: 0.92267, std: 0.00689, params: {'max_features': 5}]\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print time.clock() - start_time, \"seconds\"\n",
    "print grid_search.grid_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.96      0.93      1708\n",
      "Churn = yes       0.59      0.31      0.41       292\n",
      "\n",
      "avg / total       0.85      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh3.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn3 = neigh3.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn3)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.98      0.93      1708\n",
      "Churn = yes       0.74      0.30      0.42       292\n",
      "\n",
      "avg / total       0.87      0.88      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh5.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn5 = neigh5.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn5)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn5, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_length', 0.032714086486697193),\n",
       " ('number_vmail_messages', 0.018511842395402541),\n",
       " ('total_day_minutes', 0.12925761511427303),\n",
       " ('total_day_calls', 0.029914894511634791),\n",
       " ('total_day_charge', 0.12430612418793403),\n",
       " ('total_eve_minutes', 0.054826845285946169),\n",
       " ('total_eve_calls', 0.029263641808383319),\n",
       " ('total_eve_charge', 0.056820398828194528),\n",
       " ('total_night_minutes', 0.036781939282099857),\n",
       " ('total_night_calls', 0.029265855284399546),\n",
       " ('total_night_charge', 0.036830917962184725),\n",
       " ('total_intl_minutes', 0.040537449994534298),\n",
       " ('total_intl_calls', 0.046876264649391389),\n",
       " ('total_intl_charge', 0.040834237349056751),\n",
       " ('number_customer_service_calls', 0.10109659136782007),\n",
       " ('state_AK', 0.00076081562307830323),\n",
       " ('state_AL', 0.00076211823146704106),\n",
       " ('state_AR', 0.0021403504277965053),\n",
       " ('state_AZ', 0.001714373196587398)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show importance of each feature in Random Forest\n",
    "zip(df.columns[1:20], rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.920\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsgRhjDHGK0sQxhhjvLIEYYwxxqv/D84+RkfRcXOxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1140bfd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print 'ROC AUC: %0.3f' % roc_auc\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.87      0.99      0.92      1708\n",
      "        Yes       0.63      0.12      0.21       292\n",
      "\n",
      "avg / total       0.83      0.86      0.82      2000\n",
      "\n",
      "[[1687   21]\n",
      " [ 256   36]]\n",
      "0.8615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='auto')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print accuracy_score(expected,predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVC kernel= linear\n",
    "#Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:85: DeprecationWarning: gamma=0.0 has been deprecated in favor of gamma='auto' as of 0.17. Backward compatibility for gamma=0.0 will be removed in 0.18\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:85: DeprecationWarning: gamma=0.0 has been deprecated in favor of gamma='auto' as of 0.17. Backward compatibility for gamma=0.0 will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.76      0.85      1708\n",
      "        Yes       0.36      0.80      0.50       292\n",
      "\n",
      "avg / total       0.87      0.77      0.80      2000\n",
      "\n",
      "[[1298  410]\n",
      " [  58  234]]\n",
      "0.766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='auto',gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Cost Function (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-286ab53ee5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"SCORES\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"BEST SCORE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[.01,.05,1,2,3,4,5,9,10]}\n",
    "svr = SVC(kernel='linear')\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST SCORE\", grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Several Functions (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[.001,.01,1,3,5,10]}\n",
    "svr = SVC()\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST Estm\",grid_svm.best_estimator_ \n",
    "print \"BEST SCORE\",grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#How does \"Best\" perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='auto',gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=1.0,class_weight='auto',gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_rbf,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_rbf))\n",
    "print accuracy_score(expected,predicted_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.92      0.92      0.92      1708\n",
      "        Yes       0.53      0.53      0.53       292\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2000\n",
      "\n",
      "[[1569  139]\n",
      " [ 137  155]]\n",
      "0.862\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost Classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.7, max_depth=1, random_state=0)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))\n",
    "print accuracy_score(expected,predicted_GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#AdaBoost of a Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_bdt,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bdt))\n",
    "print accuracy_score(expected,predicted_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=100),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.02,\n",
    "    n_iter=10)\n",
    "nn.fit(features_train, target_train)\n",
    "\n",
    "y_valid = nn.predict(features_test)\n",
    "\n",
    "score = nn.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

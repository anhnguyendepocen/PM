{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mylesgartland/Documents/Courses/Data Mining/Week 5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add packages\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/Documents/Courses/Data Mining/Week 5\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mylesgartland/Documents/Courses/Data Mining/Week 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "# Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'state', u'account_length', u'area_code', u'international_plan',\n",
      "       u'voice_mail_plan', u'number_vmail_messages', u'total_day_minutes',\n",
      "       u'total_day_calls', u'total_day_charge', u'total_eve_minutes',\n",
      "       u'total_eve_calls', u'total_eve_charge', u'total_night_minutes',\n",
      "       u'total_night_calls', u'total_night_charge', u'total_intl_minutes',\n",
      "       u'total_intl_calls', u'total_intl_charge',\n",
      "       u'number_customer_service_calls', u'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Target\n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x117c97950>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQS9JjTPoJalxBr0kNe7/A9HPOTMfL4IlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c9e3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.ix[:,1:].values, df.ix[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print features_test.shape\n",
    "print features_train.shape\n",
    "print target_test.shape\n",
    "print target_train.shape\n",
    "print \"Percent of Target that is Yes\", target_test.mean()\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.9225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.95      0.96      0.95      1708\n",
      " Fail = yes       0.74      0.72      0.73       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print \"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt)\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.92026578  0.910299    0.93023256  0.94019934  0.92026578  0.93979933\n",
      "  0.909699    0.92976589  0.93311037  0.89966555]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92333025922510248"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print \"Cross Validation Score for each K\",scores\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1634   74]\n",
      " [  81  211]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c0a2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      0.99      0.97      1708\n",
      "Churn = yes       0.95      0.68      0.79       292\n",
      "\n",
      "avg / total       0.95      0.95      0.94      2000\n",
      "\n",
      "[[1698   10]\n",
      " [  94  198]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_rf)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94684385  0.94352159  0.95016611  0.96013289  0.94352159  0.94648829\n",
      "  0.95317726  0.93979933  0.94648829  0.95652174]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94866609628995879"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score for each K\",scores_rf\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1698   10]\n",
      " [  94  198]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118d1df50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.739679 seconds\n",
      "[mean: 0.88967, std: 0.00843, params: {'max_features': 2}, mean: 0.90167, std: 0.00628, params: {'max_features': 3}, mean: 0.91167, std: 0.01060, params: {'max_features': 4}, mean: 0.92167, std: 0.00922, params: {'max_features': 5}]\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print time.clock() - start_time, \"seconds\"\n",
    "print grid_search.grid_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.96      0.93      1708\n",
      "Churn = yes       0.59      0.31      0.41       292\n",
      "\n",
      "avg / total       0.85      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh3.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn3 = neigh3.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn3)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.98      0.93      1708\n",
      "Churn = yes       0.74      0.30      0.42       292\n",
      "\n",
      "avg / total       0.87      0.88      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh5.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn5 = neigh5.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn5)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn5, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_length', 0.032699064205486038),\n",
       " ('number_vmail_messages', 0.019149123580139503),\n",
       " ('total_day_minutes', 0.12325713666568326),\n",
       " ('total_day_calls', 0.029331292990522735),\n",
       " ('total_day_charge', 0.12863515020058522),\n",
       " ('total_eve_minutes', 0.05329918232360923),\n",
       " ('total_eve_calls', 0.029638397613275469),\n",
       " ('total_eve_charge', 0.055570372948396098),\n",
       " ('total_night_minutes', 0.037005109713175735),\n",
       " ('total_night_calls', 0.030241934044242576),\n",
       " ('total_night_charge', 0.036976169130996876),\n",
       " ('total_intl_minutes', 0.040420958833006178),\n",
       " ('total_intl_calls', 0.045567053548251524),\n",
       " ('total_intl_charge', 0.041184771233170089),\n",
       " ('number_customer_service_calls', 0.10222415854996661),\n",
       " ('state_AK', 0.00076780052956094947),\n",
       " ('state_AL', 0.00080534576699630431),\n",
       " ('state_AR', 0.0018644058545278673),\n",
       " ('state_AZ', 0.0019461666590542884)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show importance of each feature in Random Forest\n",
    "zip(df.columns[1:20], rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.922\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11902c110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print 'ROC AUC: %0.3f' % roc_auc\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.87      0.99      0.93      1708\n",
      "        Yes       0.70      0.11      0.19       292\n",
      "\n",
      "avg / total       0.84      0.86      0.82      2000\n",
      "\n",
      "[[1694   14]\n",
      " [ 259   33]]\n",
      "0.8635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='balanced')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print accuracy_score(expected,predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVC kernel= linear\n",
    "#Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma=0.1)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.74      0.84      1708\n",
      "        Yes       0.35      0.80      0.49       292\n",
      "\n",
      "avg / total       0.87      0.75      0.79      2000\n",
      "\n",
      "[[1271  437]\n",
      " [  57  235]]\n",
      "0.753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search of Cost Function (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [mean: 0.86167, std: 0.00000, params: {'C': 0.01}, mean: 0.86167, std: 0.00000, params: {'C': 0.05}, mean: 0.86200, std: 0.00067, params: {'C': 1}, mean: 0.87167, std: 0.00350, params: {'C': 5}, mean: 0.87300, std: 0.00386, params: {'C': 10}, mean: 0.87133, std: 0.00542, params: {'C': 15}]\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[.01,.05,1,5,10,15]}\n",
    "svr = SVC(kernel='linear')\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST SCORE\", grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Several Functions (with cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#How does \"Best\" perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.71      0.82      1708\n",
      "        Yes       0.32      0.79      0.46       292\n",
      "\n",
      "avg / total       0.86      0.73      0.76      2000\n",
      "\n",
      "[[1221  487]\n",
      " [  62  230]]\n",
      "0.7255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned.\n",
    "Not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours\n",
    "NOT SHOWN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.92      0.95      0.93      1708\n",
      "        Yes       0.64      0.50      0.56       292\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2000\n",
      "\n",
      "[[1624   84]\n",
      " [ 145  147]]\n",
      "0.8855\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost Classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))\n",
    "print accuracy_score(expected,predicted_GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.98      0.97      1708\n",
      "        Yes       0.88      0.74      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1680   28]\n",
      " [  77  215]]\n",
      "0.9475\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost of a Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_bdt,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bdt))\n",
    "print accuracy_score(expected,predicted_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91608392  0.919       0.90690691]\n",
      "0.913996940997\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got 'churn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ab7f683b7aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mscores_xtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mscores_xtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_xtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_xtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_xtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((x,))\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 236\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got 'churn'"
     ]
    }
   ],
   "source": [
    "#Extra Trees- Extremely Random Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xtree = DecisionTreeClassifier(max_depth=None, min_samples_split=1,\n",
    "random_state=0)\n",
    "xtree.fit(features_train, target_train)\n",
    "predicted_xtree=xtree.predict(features_test)\n",
    "scores_xtree=cross_val_score(xtree, features_train, target_train,n_jobs=-1)\n",
    "print scores_xtree\n",
    "print scores_xtree.mean() \n",
    "print(classification_report(expected, predicted_xtree,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_xtree))\n",
    "print accuracy_score(expected,predicted_xtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94605395  0.954       0.94394394]\n",
      "0.947999296666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.99      0.97      1708\n",
      "        Yes       0.91      0.72      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1686   22]\n",
      " [  82  210]]\n",
      "0.948\n"
     ]
    }
   ],
   "source": [
    "#Standard Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "#as with all models, there are lots of arguments to adjust\n",
    "bag=BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, \n",
    "                      max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, \n",
    "                      warm_start=False, n_jobs=-1, random_state=None, verbose=0)\n",
    "bag.fit(features_train, target_train)\n",
    "predicted_bag=bag.predict(features_test)\n",
    "scores_bag = cross_val_score(bag, features_train, target_train)\n",
    "print scores_bag\n",
    "print scores_bag.mean()\n",
    "print(classification_report(expected, predicted_bag,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bag))\n",
    "print accuracy_score(expected,predicted_bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88311688  0.882       0.86286286]\n",
      "0.87599324866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.91      0.95      0.93      1708\n",
      "        Yes       0.64      0.46      0.54       292\n",
      "\n",
      "avg / total       0.87      0.88      0.88      2000\n",
      "\n",
      "[[1631   77]\n",
      " [ 157  135]]\n",
      "0.883\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Only\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(features_train, target_train)\n",
    "predicted_ada=ada.predict(features_test)\n",
    "scores_ada = cross_val_score(ada, features_train, target_train)\n",
    "print scores_ada\n",
    "print scores_ada.mean()\n",
    "print(classification_report(expected, predicted_ada,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_ada))\n",
    "print accuracy_score(expected,predicted_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81518482  0.356       0.86786787]\n",
      "0.679684227684\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      0.99      0.92      1708\n",
      "        Yes       0.54      0.04      0.08       292\n",
      "\n",
      "avg / total       0.81      0.85      0.80      2000\n",
      "\n",
      "[[1697   11]\n",
      " [ 279   13]]\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "#Stocastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#as with all models, there are lots of arguments to adjust\n",
    "SGD=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced', epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=-1,\n",
    "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
    "       verbose=0, warm_start=False)\n",
    "SGD.fit(features_train, target_train)\n",
    "predicted_SGD=SGD.predict(features_test)\n",
    "scores_SGD = cross_val_score(SGD, features_train, target_train)\n",
    "print scores_SGD\n",
    "print scores_SGD.mean()\n",
    "print(classification_report(expected, predicted_SGD,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SGD))\n",
    "print accuracy_score(expected,predicted_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.93 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.59 (+/- 0.07) [naive Bayes]\n",
      "Accuracy: 0.90 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "#Majority Voting\n",
    "#A form of Stacking\n",
    "#Note you don't have to put in the packages each time, only once per session\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#Three Models Log Reg, RF and NB\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for MV, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_validation.cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

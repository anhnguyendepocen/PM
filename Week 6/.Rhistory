###################
#First with Rpart
library(rpart)
library(caret)
BC.rpart <- rpart(Class~.,data=bc_train, maxdepth=3)
print(BC.rpart)
summary(BC.rpart)
#confusion matrix for rpart
actual <- bc_test$Class #created to test the "test" data/
rpart_predicted <- predict(BC.rpart, bc_test, type="class")
rpart_results.matrix <- confusionMatrix(rpart_predicted, actual) #the model vs the actual holdout data.
print(rpart_results.matrix) #look at my diagnostics
#use all your other DT diagnostics and plots here
#random forest decision tree with default settings
library(caret)
library(randomForest)
set.seed(59)
bc_rf <- randomForest(Class ~.,data=bc_train, ntree=500,na.action = na.omit, importance=TRUE)
print(bc_rf) #shows OOB of model and confusion matrix
importance(bc_rf) #shows the importance of each variable
varImpPlot(bc_rf) #plots the importance of each variable
#Confusion Matrix for RF
actual <- bc_test$Class #this is just a repeat of the above
bc_rf_predict<-predict(bc_rf, bc_test,type="response")
rf_results.matrix <- confusionMatrix(bc_rf_predict, actual,positive="malignant") #the model vs the actual holdout data.
print(rf_results.matrix)
#Create a ROC curve
library(ROCR)
bc_rf_predict_prob<-predict(bc_rf, type="prob", bc_test)# same as above for predict, but add "prob".
bc.pred = prediction(bc_rf_predict_prob[,2],bc_test$Class)#use [,2] to pick the malignant class prob
bc.rf.perf = performance(bc.pred,"tpr","fpr") #true pos and false pos
plot(bc.rf.perf ,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
install.packages("ROCR")
#Create a ROC curve
library(ROCR)
bc_rf_predict_prob<-predict(bc_rf, type="prob", bc_test)# same as above for predict, but add "prob".
bc.pred = prediction(bc_rf_predict_prob[,2],bc_test$Class)#use [,2] to pick the malignant class prob
bc.rf.perf = performance(bc.pred,"tpr","fpr") #true pos and false pos
plot(bc.rf.perf ,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
library(ROCR)
bc.auc <- performance(bc.pred, measure = "auc") #run an area under the curve
str(bc.auc) #see different values in the auc object
as.numeric(bc.auc@y.values) #shows the AUC percentage
install.packages("doSNOW")
library(caret)
library(doSNOW) #to parallel the process
registerDoSNOW(makeCluster(2, type = "SOCK")) #sets to use all 4 cores in my laptop
ctrl <- trainControl(method = "repeatedcv",
number = 5, repeats = 5) #sets crossvalidation
set.seed(59)
bc_rf_trained <- train(Class ~.,data=bc_train, method = "rf",
metric = "Kappa", trControl = ctrl) #method is randomforest. Added in the cv.
print(bc_rf_trained)
library(caret)
grid_rf <- expand.grid(.mtry = c(4, 9, 16, 25)) #mtry is how many variables it randomly tries at each node
set.seed(59)
ptm <- proc.time() #starts to time
bc_rf_trained2 <- train(Class ~.,data=bc_train, method = "rf", ntree=500,
metric = "Kappa", trControl = ctrl, tuneGrid = grid_rf) #also control mtry
print(bc_rf_trained2)
proc.time() - ptm
summary(bc_rf_trained2)
data("iris")
train <- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test <- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
knn(train, test, cl, k = 3, prob=TRUE)
library(class)
knn(train, test, cl, k = 3, prob=TRUE)
attributes(.Last.value)
library(mlbench) #has the Breast Cancer dataset in it
library(caret)
data(BreastCancer)
#?BreastCancer #see the format of the data
bc_changed<-BreastCancer[2:11] #removes variables not to be used
bc_changed$Class<-factor(bc_changed$Class) #changes the target to a factor (if needed)
#Create train and test/holdout samples
set.seed(59)
bc_rand <- bc_changed[order(runif(699)), ] #699 observations
bc_rand <- sample(1:699, 499) #want 499 in training and the rest in test. that is about a 70/30
bc_train <- bc_changed[ bc_rand,]
bc_test  <- bc_changed[-bc_rand,]
###################
#First with Rpart
library(rpart)
library(caret)
BC.rpart <- rpart(Class~.,data=bc_train, maxdepth=3)
print(BC.rpart)
summary(BC.rpart)
#confusion matrix for rpart
actual <- bc_test$Class #created to test the "test" data/
rpart_predicted <- predict(BC.rpart, bc_test, type="class")
rpart_results.matrix <- confusionMatrix(rpart_predicted, actual) #the model vs the actual holdout data.
print(rpart_results.matrix) #look at my diagnostics
#use all your other DT diagnostics and plots here
#random forest decision tree with default settings
library(caret)
library(randomForest)
set.seed(59)
bc_rf <- randomForest(Class ~.,data=bc_train, ntree=500,na.action = na.omit, importance=TRUE)
print(bc_rf) #shows OOB of model and confusion matrix
importance(bc_rf) #shows the importance of each variable
varImpPlot(bc_rf) #plots the importance of each variable
#Confusion Matrix for RF
actual <- bc_test$Class #this is just a repeat of the above
bc_rf_predict<-predict(bc_rf, bc_test,type="response")
rf_results.matrix <- confusionMatrix(bc_rf_predict, actual,positive="malignant") #the model vs the actual holdout data.
print(rf_results.matrix)
library(ROCR)
bc_rf_predict_prob<-predict(bc_rf, type="prob", bc_test)# same as above for predict, but add "prob".
bc.pred = prediction(bc_rf_predict_prob[,2],bc_test$Class)#use [,2] to pick the malignant class prob
bc.rf.perf = performance(bc.pred,"tpr","fpr") #true pos and false pos
plot(bc.rf.perf ,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
library(ROCR)
bc.auc <- performance(bc.pred, measure = "auc") #run an area under the curve
str(bc.auc) #see different values in the auc object
as.numeric(bc.auc@y.values) #shows the AUC percentage
registerDoSNOW(makeCluster(2, type = "SOCK")) #sets to use all 4 cores in my laptop
ctrl <- trainControl(method = "repeatedcv",
number = 5, repeats = 5) #sets crossvalidation
set.seed(59)
bc_rf_trained <- train(Class ~.,data=bc_train, method = "rf",
metric = "Kappa", trControl = ctrl) #method is randomforest. Added in the cv.
print(bc_rf_trained)
bc_rf_trained <- train(Class ~.,data=bc_train, method = "rf",
metric = "Kappa", trControl = ctrl) #method is randomforest. Added in the cv.
print(bc_rf_trained)
set.seed(59)
ptm <- proc.time() #starts to time
bc_rf_trained2 <- train(Class ~.,data=bc_train, method = "rf", ntree=500,
metric = "Kappa", trControl = ctrl, tuneGrid = grid_rf) #also control mtry
print(bc_rf_trained2)
proc.time() - ptm
summary(bc_rf_trained2)
install.packages("ncvreg")
data(prostate)
library("ncvreg", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
data(prostate)
View(prostate)
write.csv(prostate, file = "prostate.csv")
install.packages("glmnet")
library(glmnet)
# Gaussian
x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fit1=glmnet(x,y)
print(fit1)
coef(fit1,s=0.01) # extract coefficients at a single value of lambda
predict(fit1,newx=x[1:10,],s=c(0.01,0.005)) # make predictions
#SVM USING R
Churn_Calls <- read.csv("~/Documents/Courses/Data Mining/Week 5/Churn_Calls.csv")
#Popular SVM algo in e1071
library(e1071)
library(MASS)
names(Churn_Calls)
#Build SVM for Churn
#Create test and train
index <- 1:nrow(Churn_Calls)
testindex <- sample(index, trunc(length(index)/3))
testset <- Churn_Calls[testindex,]
trainset <- Churn_Calls[-testindex,]
#Model with some arguments
model2 <- svm(churn~., data = trainset,kernel = "linear", gamma = 0.1, cost = 10, k=5, type='C')
print(model2)
summary(model2)
#for details on argument
?svm
#USING CARET
library(caret)
actual <- testset[,20]
svm_predict<-predict(model2, testset,type="response")
svm_results.matrix <- confusionMatrix(svm_predict, actual, positive="yes")
print(svm_results.matrix)
#Tuning
tuned <- tune.svm(churn~., data = trainset, gamma = 10^(-6:-1), cost = 10^(-1:1))
summary(tuned)
library("neuralnet")
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
## Step 2: Exploring and preparing the data ----
# read in data and examine structure
concrete <- read.csv("concrete.csv")
str(concrete)
boxplot(concrete) #see the distibutions of each variable
#custom normalization function
#This is called min/max normalization (vs z-score)
#Normalization by Scaling Between 0 and 1
#Common way for ANN
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply min/max normalization to entire data frame
#note all values are now between 0 and 1
concrete_norm <- as.data.frame(lapply(concrete, normalize))
# confirm that the range is now between zero and one
summary(concrete_norm$strength)
# compared to the original minimum and maximum
summary(concrete$strength)
# create training and test data
#Split the dataset into a training and testing sets 70/30
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
## Step 3: Training a model on the data ----
# train the neuralnet model
library(neuralnet)
# simple ANN with only a two hidden neurons
concrete_model_2 <- neuralnet(formula = strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 2, algorithm = "rprop+", learningrate=NULL)
#rprop+ is a backpropagation method called resilient backpropagation. It modifies
#its learning rate on the error.
# visualize the network topology
#note one node in the hidden layer
plot(concrete_model_2)
#table of nuerons and weights
concrete_model_2$result.matrix
## Step 4: Evaluating model performance ----
# obtain model results
model_results_2 <- compute(concrete_model_2, concrete_test[1:8]) #You are running the training set through the ANN model
# obtain predicted strength values
predicted_strength_2 <- model_results_2$net.result #The prediction of each observation
# examine the correlation between predicted and actual values
cor(predicted_strength_2, concrete_test$strength)
## Step 5: Improving model performance ----
# a more complex neural network topology with 5 hidden neurons
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 5,algorithm = "rprop+", learningrate=NULL)
# plot the network
#note 5 neurons in the hidden layer
plot(concrete_model2)
# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
predicted_strength2[1:10]
#what do you notice about the values?
#Return norm value to a regular value
denormalize <- function(x) {
return(x*(max(concrete$strength)) - min(concrete$strength))+min(concrete$strength)
}
#look at predicted vs actual
accuracy<-data.frame(denormalize(predicted_strength2),concrete$strength[774:1030])
#plot pred vs actual
plot(denormalize(predicted_strength2),concrete$strength[774:1030])
#Model with two hidden layers
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(3,3), algorithm = "rprop+", learningrate=NULL)
plot(concrete_model3)
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
library("neuralnet")
# you can also see the packages nnet and RSNNS
dataset <- read.csv("creditset.csv")
head(dataset)
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
print(creditnet)
## plot the NN
plot(creditnet, rep = "best")
#weight from models
creditnet$weights
creditnet$result.matrix
#results (notice in probabilities)
creditnet$net.result
## test the resulting output
temp_test <- subset(testset, select = c("LTI", "age"))
#compute the test results through the ANN model
creditnet.results <- compute(creditnet, temp_test)
#Make a table to predictions and actuals
results <- data.frame(actual = testset$default10yr,
prediction = creditnet.results$net.result)
print(results)
#Round predictions to make easier to read
results$prediction <- round(results$prediction)
#See partial results
results[100:115, ]
#See all results
print(results)
print(creditnet.results)
#USing Gmodels to create a confusion matrix
library(gmodels)
CrossTable(results$actual, results$prediction)
################################################
#Arguments in neural net function
neuralnet(formula, data, hidden = 1, threshold = 0.01,
stepmax = 1e+05, rep = 1, startweights = NULL,
learningrate.limit = NULL,
learningrate.factor = list(minus = 0.5, plus = 1.2),
learningrate=NULL, lifesign = "none",
lifesign.step = 1000, algorithm = "rprop+",
err.fct = "sse", act.fct = "logistic",
linear.output = TRUE, exclude = NULL,
constant.weights = NULL, likelihood = FALSE)
#######################################################
#two hidden layers of 2 and 4 nodes.
creditnet1 <- neuralnet(default10yr ~ LTI +age, trainset, hidden=c(2,4), lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
print(creditnet1)
plot(creditnet1)
###Try happends are you add/less more hidden node, more variables, and changes in arguments
#In neural networks it is good idea not just normalize data, but also to scale them.
#This is intended for faster approaching to global minima at error surface.
#Common way for ANN
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply min/max normalization to entire data frame
#note all values are now between 0 and 1
creditset_norm <- as.data.frame(lapply(creditset, normalize))
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
library("neuralnet")
# you can also see the packages nnet and RSNNS
dataset <- read.csv("creditset.csv")
#ANN using a binominal target
set.seed(1234567890)
library("neuralnet")
creditset <- read.csv("~/Documents/Documents/Courses/Predictive Models/Week 5/creditset.csv")
head(creditset)
#Common way for ANN
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply min/max normalization to entire data frame
#note all values are now between 0 and 1
creditset_norm <- as.data.frame(lapply(creditset, normalize))
## extract a set to train the NN
trainset <- creditset_norm[1:800, ]
## select the test set
testset <- creditset_norm[801:2000, ]
#ANN with two inputs and 1 output (2 class target)
creditnet <- neuralnet(default10yr ~ LTI + age +income+ loan, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)
plot(creditnet, rep = "best")
## test the resulting output
#temp_test <- subset(testset, select = c("LTI", "age",))
creditnet.results <- compute(creditnet, testset)
results <- data.frame(actual = testset$default10yr, prediction = creditnet.results$net.result)
results[100:115, ]
#We can round to the nearest integer to improve readability:
results$prediction <- round(results$prediction)
results[100:115, ]
library(caret)
#confusion matrix for rpart
actual <- testset$default10yr #created to test the "test" data/
ann_predicted <- predict(creditnet, testset, type="class")
ann_results.matrix <- confusionMatrix(results$prediction, actual) #the model vs the actual holdout data.
print(ann_results.matrix) #look at my diagnostics
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
## Step 2: Exploring and preparing the data ----
# read in data and examine structure
concrete <- read.csv("concrete.csv")
str(concrete)
boxplot(concrete) #see the distibutions of each variable
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm$strength)
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
library(neuralnet)
concrete_model_2 <- neuralnet(formula = strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 2, algorithm = "rprop+", learningrate=NULL)
#
plot(concrete_model_2)
concrete_model_2$result.matrix
model_results_2 <- compute(concrete_model_2, concrete_test[1:8]) #You are running the training set through the ANN model
predicted_strength_2 <- model_results_2$net.result #The prediction of each observation
cor(predicted_strength_2, concrete_test$strength)
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 5,algorithm = "rprop+", learningrate=NULL)
plot(concrete_model2)
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(3,3), algorithm = "rprop+", learningrate=NULL)
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(3,3), algorithm = "rprop+", learningrate=NULL)
plot(concrete_model3)
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(5,3), algorithm = "rprop+", learningrate=NULL)
plot(concrete_model3)
plot(concrete_model3)
set.seed(1234567890)
library("neuralnet")
creditset <- read.csv("~/Documents/Documents/Courses/Predictive Models/Week 5/creditset.csv")
head(creditset)
creditset <- read.csv("~/mylesgartland/Documents/Courses/Predictive Models/Week 5/creditset.csv")
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
creditset <- read.csv("creditset.csv")
head(creditset)
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply min/max normalization to entire data frame
#note all values are now between 0 and 1
creditset_norm <- as.data.frame(lapply(creditset, normalize))
## extract a set to train the NN
trainset <- creditset_norm[1:800, ]
## select the test set
testset <- creditset_norm[801:2000, ]
creditnet <- neuralnet(default10yr ~ LTI + age +income+ loan, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)
plot(creditnet, rep = "best")
library(caret)
#confusion matrix for rpart
actual <- testset$default10yr #created to test the "test" data/
ann_predicted <- predict(creditnet, testset, type="class")
ann_results.matrix <- confusionMatrix(results$prediction, actual) #the model vs the actual holdout data.
print(ann_results.matrix) #look at my diagnostics
creditnet.results <- compute(creditnet, testset)
results <- data.frame(actual = testset$default10yr, prediction = creditnet.results$net.result)
results[100:115, ]
#We can round to the nearest integer to improve readability:
results$prediction <- round(results$prediction)
results[100:115, ]
library(caret)
#confusion matrix for rpart
actual <- testset$default10yr #created to test the "test" data/
ann_predicted <- predict(creditnet, testset, type="class")
ann_results.matrix <- confusionMatrix(results$prediction, actual) #the model vs the actual holdout data.
print(ann_results.matrix) #look at my diagnostics
setwd('/Users/mylesgartland/Documents/Courses/Predictive Models/Week 5')
library("neuralnet")
# you can also see the packages nnet and RSNNS
dataset <- read.csv("creditset.csv")
head(dataset)
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
print(creditnet)
## plot the NN
plot(creditnet, rep = "best")
#weight from models
creditnet$weights
creditnet$result.matrix
#results (notice in probabilities)
creditnet$net.result
## test the resulting output
temp_test <- subset(testset, select = c("LTI", "age"))
#compute the test results through the ANN model
creditnet.results <- compute(creditnet, temp_test)
#Make a table to predictions and actuals
results <- data.frame(actual = testset$default10yr,
prediction = creditnet.results$net.result)
print(results)
#Round predictions to make easier to read
results$prediction <- round(results$prediction)
#See partial results
results[100:115, ]
#See all results
print(results)
print(creditnet.results)
#USing Gmodels to create a confusion matrix
library(gmodels)
CrossTable(results$actual, results$prediction)
################################################
#Arguments in neural net function
neuralnet(formula, data, hidden = 1, threshold = 0.01,
stepmax = 1e+05, rep = 1, startweights = NULL,
learningrate.limit = NULL,
learningrate.factor = list(minus = 0.5, plus = 1.2),
learningrate=NULL, lifesign = "none",
lifesign.step = 1000, algorithm = "rprop+",
err.fct = "sse", act.fct = "logistic",
linear.output = TRUE, exclude = NULL,
constant.weights = NULL, likelihood = FALSE)
#######################################################
#two hidden layers of 2 and 4 nodes.
creditnet1 <- neuralnet(default10yr ~ LTI +age, trainset, hidden=c(2,4), lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
print(creditnet1)
plot(creditnet1)
###Try happends are you add/less more hidden node, more variables, and changes in arguments
#In neural networks it is good idea not just normalize data, but also to scale them.
#This is intended for faster approaching to global minima at error surface.
#Common way for ANN
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply min/max normalization to entire data frame
#note all values are now between 0 and 1
creditset_norm <- as.data.frame(lapply(creditset, normalize))
library(gmodels)
CrossTable(results$actual, results$prediction)

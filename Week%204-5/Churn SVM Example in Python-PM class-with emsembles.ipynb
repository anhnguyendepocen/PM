{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mpgartland/Documents/Courses/Predictive Models/PM/Week 4-5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add packages\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland/Documents/Courses/Predictive Models/PM/Week 4-5\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mpgartland/Documents/Courses/Predictive Models/PM/Week 4-5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "# Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'state', u'account_length', u'area_code', u'international_plan',\n",
      "       u'voice_mail_plan', u'number_vmail_messages', u'total_day_minutes',\n",
      "       u'total_day_calls', u'total_day_charge', u'total_eve_minutes',\n",
      "       u'total_eve_calls', u'total_eve_charge', u'total_night_minutes',\n",
      "       u'total_night_calls', u'total_night_charge', u'total_intl_minutes',\n",
      "       u'total_intl_calls', u'total_intl_charge',\n",
      "       u'number_customer_service_calls', u'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Target\n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x11669c090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQS9JjTPoJalxBr0kNe7/A9HPOTMfL4IlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116650ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.ix[:,1:].values, df.ix[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print features_test.shape\n",
    "print features_train.shape\n",
    "print target_test.shape\n",
    "print target_train.shape\n",
    "print \"Percent of Target that is Yes\", target_test.mean()\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.9225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.96      0.95      0.95      1708\n",
      " Fail = yes       0.73      0.74      0.74       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print \"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt)\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.92358804  0.89700997  0.92358804  0.9269103   0.91694352  0.94314381\n",
      "  0.909699    0.9264214   0.93311037  0.909699  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92101134457049516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print \"Cross Validation Score for each K\",scores\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1628   80]\n",
      " [  75  217]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1058314d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      1.00      0.97      1708\n",
      "Churn = yes       0.97      0.70      0.81       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1702    6]\n",
      " [  89  203]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_rf)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94684385  0.94019934  0.95348837  0.96345515  0.94019934  0.95317726\n",
      "  0.95317726  0.94648829  0.94983278  0.95652174]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95033833709263449"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score for each K\",scores_rf\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1702    6]\n",
      " [  89  203]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a63a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.354098 seconds\n",
      "[mean: 0.89100, std: 0.00703, params: {'max_features': 2}, mean: 0.90200, std: 0.00449, params: {'max_features': 3}, mean: 0.91467, std: 0.01059, params: {'max_features': 4}, mean: 0.92467, std: 0.00890, params: {'max_features': 5}]\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print time.clock() - start_time, \"seconds\"\n",
    "print grid_search.grid_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.96      0.93      1708\n",
      "Churn = yes       0.59      0.31      0.41       292\n",
      "\n",
      "avg / total       0.85      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh3.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn3 = neigh3.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn3)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.98      0.93      1708\n",
      "Churn = yes       0.74      0.30      0.42       292\n",
      "\n",
      "avg / total       0.87      0.88      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh5.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn5 = neigh5.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn5)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn5, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_length', 0.032506628021268483),\n",
       " ('number_vmail_messages', 0.016079749473477182),\n",
       " ('total_day_minutes', 0.12725737590033287),\n",
       " ('total_day_calls', 0.029697073839324982),\n",
       " ('total_day_charge', 0.12646065487498184),\n",
       " ('total_eve_minutes', 0.055534221890246684),\n",
       " ('total_eve_calls', 0.028477187735003764),\n",
       " ('total_eve_charge', 0.05478028405720365),\n",
       " ('total_night_minutes', 0.036853523182761784),\n",
       " ('total_night_calls', 0.028787265886193396),\n",
       " ('total_night_charge', 0.036470152704505841),\n",
       " ('total_intl_minutes', 0.041784768912667615),\n",
       " ('total_intl_calls', 0.046841756216550789),\n",
       " ('total_intl_charge', 0.040572686754162847),\n",
       " ('number_customer_service_calls', 0.10273572898086834),\n",
       " ('state_AK', 0.0007426579785588445),\n",
       " ('state_AL', 0.00069816949839634807),\n",
       " ('state_AR', 0.0018337591984110531),\n",
       " ('state_AZ', 0.0019249459800578161)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show importance of each feature in Random Forest\n",
    "zip(df.columns[1:20], rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.921\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n45UlCGOMMV79f//js2tS1ROBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119270e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print 'ROC AUC: %0.3f' % roc_auc\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       0.83      0.02      0.03       292\n",
      "\n",
      "avg / total       0.85      0.86      0.79      2000\n",
      "\n",
      "[[1707    1]\n",
      " [ 287    5]]\n",
      "0.856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='balanced')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print accuracy_score(expected,predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC kernel= linear\n",
    "# Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma=0.1)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.74      0.84      1708\n",
      "        Yes       0.35      0.80      0.49       292\n",
      "\n",
      "avg / total       0.87      0.75      0.79      2000\n",
      "\n",
      "[[1271  437]\n",
      " [  57  235]]\n",
      "0.753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.71      0.82      1708\n",
      "        Yes       0.32      0.79      0.46       292\n",
      "\n",
      "avg / total       0.86      0.73      0.76      2000\n",
      "\n",
      "[[1221  487]\n",
      " [  62  230]]\n",
      "0.7255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned.\n",
    "Not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours\n",
    "NOT SHOWN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.92      0.95      0.93      1708\n",
      "        Yes       0.64      0.50      0.56       292\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2000\n",
      "\n",
      "[[1624   84]\n",
      " [ 145  147]]\n",
      "0.8855\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost Classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))\n",
    "print accuracy_score(expected,predicted_GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.98      0.97      1708\n",
      "        Yes       0.88      0.74      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1680   28]\n",
      " [  77  215]]\n",
      "0.9475\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost of a Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_bdt,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bdt))\n",
    "print accuracy_score(expected,predicted_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91608392  0.919       0.90690691]\n",
      "0.913996940997\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.96      0.96      1708\n",
      "        Yes       0.74      0.73      0.74       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n",
      "[[1634   74]\n",
      " [  79  213]]\n",
      "0.9235\n"
     ]
    }
   ],
   "source": [
    "#Extra Trees- Extremely Random Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xtree = DecisionTreeClassifier(max_depth=None, min_samples_split=1,\n",
    "random_state=0)\n",
    "xtree.fit(features_train, target_train)\n",
    "predicted_xtree=xtree.predict(features_test)\n",
    "scores_xtree=cross_val_score(xtree, features_train, target_train,n_jobs=-1)\n",
    "print scores_xtree\n",
    "print scores_xtree.mean() \n",
    "print(classification_report(expected, predicted_xtree,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_xtree))\n",
    "print accuracy_score(expected,predicted_xtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94405594  0.945       0.93793794]\n",
      "0.942331293998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.99      0.97      1708\n",
      "        Yes       0.93      0.72      0.81       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1692   16]\n",
      " [  83  209]]\n",
      "0.9505\n"
     ]
    }
   ],
   "source": [
    "#Standard Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "#as with all models, there are lots of arguments to adjust\n",
    "bag=BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, \n",
    "                      max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, \n",
    "                      warm_start=False, n_jobs=-1, random_state=None, verbose=0)\n",
    "bag.fit(features_train, target_train)\n",
    "predicted_bag=bag.predict(features_test)\n",
    "scores_bag = cross_val_score(bag, features_train, target_train)\n",
    "print scores_bag\n",
    "print scores_bag.mean()\n",
    "print(classification_report(expected, predicted_bag,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bag))\n",
    "print accuracy_score(expected,predicted_bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88311688  0.882       0.86286286]\n",
      "0.87599324866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.91      0.95      0.93      1708\n",
      "        Yes       0.64      0.46      0.54       292\n",
      "\n",
      "avg / total       0.87      0.88      0.88      2000\n",
      "\n",
      "[[1631   77]\n",
      " [ 157  135]]\n",
      "0.883\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Only\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(features_train, target_train)\n",
    "predicted_ada=ada.predict(features_test)\n",
    "scores_ada = cross_val_score(ada, features_train, target_train)\n",
    "print scores_ada\n",
    "print scores_ada.mean()\n",
    "print(classification_report(expected, predicted_ada,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_ada))\n",
    "print accuracy_score(expected,predicted_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84715285  0.139       0.83683684]\n",
      "0.607663227997\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.90      0.92      0.91      1708\n",
      "        Yes       0.46      0.37      0.41       292\n",
      "\n",
      "avg / total       0.83      0.84      0.84      2000\n",
      "\n",
      "[[1579  129]\n",
      " [ 184  108]]\n",
      "0.8435\n"
     ]
    }
   ],
   "source": [
    "#Stocastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#as with all models, there are lots of arguments to adjust\n",
    "SGD=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced', epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=-1,\n",
    "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
    "       verbose=0, warm_start=False)\n",
    "SGD.fit(features_train, target_train)\n",
    "predicted_SGD=SGD.predict(features_test)\n",
    "scores_SGD = cross_val_score(SGD, features_train, target_train)\n",
    "print scores_SGD\n",
    "print scores_SGD.mean()\n",
    "print(classification_report(expected, predicted_SGD,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SGD))\n",
    "print accuracy_score(expected,predicted_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.93 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.59 (+/- 0.07) [naive Bayes]\n",
      "Accuracy: 0.90 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "#Majority Voting\n",
    "#A form of Stacking\n",
    "#Note you don't have to put in the packages each time, only once per session\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#Three Models Log Reg, RF and NB\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for MV, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_validation.cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
